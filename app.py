# app.py
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import io

st.set_page_config(page_title="–ò–ò–º–ø—É–ª—å—Å", layout="wide")

# ---- AUTH --- –ø—Ä–æ—Å—Ç–æ–π fallback ----
USE_ADV_AUTH = False
name = "–ò–Ω–∂–µ–Ω–µ—Ä"

try:
    import streamlit_authenticator as stauth
    import toml
    config = toml.load("config_auth.toml")
    authenticator = stauth.Authenticate(
        config['credentials'], config['cookie']['name'],
        config['cookie']['key'], config['cookie']['expiry_days']
    )
    name, auth_status, username = authenticator.login('–í—Ö–æ–¥', 'main')
    if not auth_status:
        if auth_status is False:
            st.error('–ù–µ–≤–µ—Ä–Ω—ã–π –ª–æ–≥–∏–Ω/–ø–∞—Ä–æ–ª—å')
        st.stop()
    authenticator.logout('–í—ã–π—Ç–∏', 'sidebar')
    USE_ADV_AUTH = True
except ModuleNotFoundError:
    # –ø—Ä–æ—Å—Ç–æ–π –≤—Ö–æ–¥ –±–µ–∑ –≤–Ω–µ—à–Ω–µ–≥–æ –ø–∞–∫–µ—Ç–∞
    st.sidebar.subheader("–í—Ö–æ–¥")
    st.session_state.setdefault("auth_ok", False)
    if not st.session_state["auth_ok"]:
        user = st.sidebar.text_input("–õ–æ–≥–∏–Ω", value="user1")
        pwd  = st.sidebar.text_input("–ü–∞—Ä–æ–ª—å", type="password", value="admin")
        if st.sidebar.button("–í–æ–π—Ç–∏"):
            if user == "user1" and pwd == "admin":
                st.session_state["auth_ok"] = True
            else:
                st.sidebar.error("–ù–µ–≤–µ—Ä–Ω—ã–π –ª–æ–≥–∏–Ω/–ø–∞—Ä–æ–ª—å")
        if not st.session_state["auth_ok"]:
            st.stop()
    if st.sidebar.button("–í—ã–π—Ç–∏"):
        st.session_state["auth_ok"] = False
        st.rerun()

# --- Sidebar: –ø—Ä–æ—Ñ–∏–ª—å / —Å–ø—Ä–∞–≤–∫–∞ ---
display_name = name if USE_ADV_AUTH else st.session_state.get("user_name", "–ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤")
with st.sidebar:
    st.markdown(f"### üë§ {display_name}")
    try:
        # Streamlit 1.30+ ‚Äî –µ—Å—Ç—å popover
        with st.popover("–ü—Ä–æ—Ñ–∏–ª—å –∏ —Å–ø—Ä–∞–≤–∫–∞"):
            st.write("""
**–ò–º—è:** {dn}  
**–†–æ–ª—å:** –ò–Ω–∂–µ–Ω–µ—Ä-–¥–∏–∞–≥–Ω–æ—Å—Ç  
**–ö–æ–Ω—Ç–∞–∫—Ç—ã:** ivan.ivanov@example.com

‚Äî –°–ø—Ä–∞–≤–∫–∞:
- –ê–ª–∞—Ä–º = severity ‚â• 80 –∏–ª–∏ p(defect) ‚â• 0.8  
- –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ = severity ‚â• 50 –∏–ª–∏ p(defect) ‚â• 0.5  
- –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–µ—Ñ–µ–∫—Ç–æ–≤ ‚Äî —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ `proba` –ø–æ –æ–∫–Ω–∞–º
            """.format(dn=display_name))
    except Exception:
        # –ù–∞ —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏—è—Ö –º–æ–∂–Ω–æ expander
        with st.expander("–ü—Ä–æ—Ñ–∏–ª—å –∏ —Å–ø—Ä–∞–≤–∫–∞"):
            st.write("–ò–º—è: " + display_name)
            st.write("–†–æ–ª—å: –ò–Ω–∂–µ–Ω–µ—Ä-–¥–∏–∞–≥–Ω–æ—Å—Ç")
            st.write("–ö–æ–Ω—Ç–∞–∫—Ç—ã: ivan.ivanov@example.com")
            st.write("–ê–ª–∞—Ä–º: severity ‚â• 80 –∏–ª–∏ p(defect) ‚â• 0.8")
            st.write("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: severity ‚â• 50 –∏–ª–∏ p(defect) ‚â• 0.5")


# --- PAGES --- —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω—ã, –¥–ª—è –≤–∏–¥–µ–æ - —á–∞—Å—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü –≤ –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–µ
page = st.sidebar.radio(
    "–†–∞–∑–¥–µ–ª—ã",
    ["–ò–ò–º–ø—É–ª—å—Å - –°–≤–æ–¥–∫–∞", "–¢–û–∏–† ‚Ä¢ –ñ—É—Ä–Ω–∞–ª –ø–æ–ª–æ–º–æ–∫", "–ò–ò-–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (MVP)"]
)

if page.startswith("–ò–ò–º–ø—É–ª—å—Å - –°–≤–æ–¥–∫–∞"):
    st.title("–ò–ò–º–ø—É–ª—å—Å ‚Äî –°–≤–æ–¥–∫–∞")
    st.caption("KPI, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏ –±—ã—Å—Ç—Ä—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä —Å—ã—Ä–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –¥–≤–∏–≥–∞—Ç–µ–ª—é")

    import glob, os, numpy as np, pandas as pd
    from features import read_csv_3phase, decimate
    FS_RAW = 25600

    files = sorted(glob.glob("data/raw/*.csv"))
    if not files:
        st.warning("–ü–æ–ª–æ–∂–∏—Ç–µ CSV –≤ –ø–∞–ø–∫—É data/raw/ –∏ –≤–µ—Ä–Ω–∏—Ç–µ—Å—å –Ω–∞ —ç—Ç—É —Å—Ç—Ä–∞–Ω–∏—Ü—É.")
        st.stop()

    # --- –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∞—Å—á—ë—Ç–∞ (–¥–ª—è —Å–≤–æ–¥–∫–∏ –∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤) ---
    colp = st.columns(3)
    with colp[0]:
        fs_out = st.select_slider("–ß–∞—Å—Ç–æ—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ì—Ü)", options=[2000, 3200, 5120], value=3200)
    with colp[1]:
        win_sec = st.select_slider("–û–∫–Ω–æ, —Å–µ–∫", options=[0.5, 1.0, 2.0], value=1.0)
    with colp[2]:
        thresh_warn = st.slider("–ü–æ—Ä–æ–≥ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è (severity / p)", 0, 100, 80, step=5)
    # --- —Å–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Å–µ–º —Ñ–∞–π–ª–∞–º (–∫—ç—à–∏—Ä—É–µ–º) ---
    @st.cache_data(show_spinner=True)
    def summarize(files, fs_out, win_sec, warn_thr):
        try:
            from inference import predict_csv
        except Exception:
            return None  # –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –Ω–µ—Ç ‚Äî –ø–æ–∫–∞–∂–µ–º –∑–∞–≥–ª—É—à–∫–∏

        alarms = 0
        warns = 0
        per_source = np.zeros(6, dtype=float)  # —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤
        per_device = {}  # –∞–≥—Ä–µ–≥–∞—Ç—ã –ø–æ —Ñ–∞–π–ª–∞–º

        for f in files:
            try:
                preds = predict_csv(f, fs_out=fs_out, win_sec=win_sec, overlap=0.0)
                df = pd.DataFrame(preds)
            except Exception:
                continue

            # –∫—Ä–∏—Ç–µ—Ä–∏–∏
            is_alarm = (df["severity"] >= 80) | (df["p_fault"] >= 0.8)
            is_warn  = (df["severity"] >= warn_thr) | (df["p_fault"] >= (warn_thr/100.0))

            alarms += int(is_alarm.sum())
            warns  += int(is_warn.sum())

            # —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–µ—Ñ–µ–∫—Ç–æ–≤ (–ø–æ –æ–∫–Ω–∞–º, –≥–¥–µ –µ—Å—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ)
            if "proba" in df.columns:
                probs = np.array(df.loc[is_warn, "proba"].tolist()) if is_warn.any() else np.empty((0,6))
                if probs.size:
                    per_source += probs.mean(axis=0)  # –º—è–≥–∫–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ

            per_device[os.path.basename(f)] = dict(
                alarms=int(is_alarm.sum()),
                warns=int(is_warn.sum()),
                severity_mean=float(df["severity"].mean() if "severity" in df else 0.0),
                p_fault_mean=float(df["p_fault"].mean() if "p_fault" in df else 0.0),
            )

        return dict(alarms=alarms, warns=warns, per_source=per_source, per_device=per_device)


    # —Å—Ç–∞–ª–æ
    calc_kpi = st.toggle(
        "–ü–æ—Å—á–∏—Ç–∞—Ç—å KPI –ø–æ –≤—Å–µ–º —Ñ–∞–π–ª–∞–º",
        value=False,
        help="–ó–∞–ø—É—Å–∫–∞–µ—Ç –∏–Ω—Ñ–µ—Ä–µ–Ω—Å predict_csv –ø–æ –≤—Å–µ–º CSV (–º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–ª–≥–æ). –ï—Å–ª–∏ –≤—ã–∫–ª—é—á–µ–Ω–æ ‚Äî –ø–æ–∫–∞–∂–µ–º –∑–∞–≥–ª—É—à–∫–∏."
    )
    summary = summarize(files, fs_out, win_sec, thresh_warn) if calc_kpi else None

    # --- KPI (–∑–∞–≥–ª—É—à–∫–∏, –µ—Å–ª–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –Ω–µ—Ç) ---
    c1, c2, c3, c4 = st.columns(4)
    if summary is None:
        # –Ω–µ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –º–æ–¥–µ–ª–∏ ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∑–∞–≥–ª—É—à–∫–∏
        c1.metric("–ê–ª–∞—Ä–º—ã (severity‚â•80 / p‚â•0.8)", "8")
        c2.metric("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è (‚â•"+str(thresh_warn)+")", "4")
        # ¬´–∏–∑ 1–° –¢–û–ò–†¬ª ‚Äî –∑–∞–≥–ª—É—à–∫–∞
        repairs = st.session_state.get("repair_count", 3)
        c3.metric("–£—Å—Ç—Ä–æ–π—Å—Ç–≤ –≤ —Ä–µ–º–æ–Ω—Ç–µ (1–° –¢–û–ò–†)", repairs)
        c4.metric("–î–≤–∏–≥–∞—Ç–µ–ª–µ–π –Ω–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–µ", len(files))
    else:
        c1.metric("–ê–ª–∞—Ä–º—ã (severity‚â•80 / p‚â•0.8)", f"{summary['alarms']}")
        c2.metric("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è (‚â•"+str(thresh_warn)+")", f"{summary['warns']}")
        # ¬´–∏–∑ 1–° –¢–û–ò–†¬ª ‚Äî —Å–µ–π—á–∞—Å –∑–∞–≥–ª—É—à–∫–∞, –ø–æ–∑–∂–µ —Å—é–¥–∞ –∫–æ–Ω–Ω–µ–∫—Ç–æ—Ä
        repairs = st.session_state.get("repair_count", 3)
        c3.metric("–£—Å—Ç—Ä–æ–π—Å—Ç–≤ –≤ —Ä–µ–º–æ–Ω—Ç–µ (1–° –¢–û–ò–†)", repairs)
        c4.metric("–î–≤–∏–≥–∞—Ç–µ–ª–µ–π –Ω–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–µ", len(files))

        # –∫—Ä—É–≥–æ–≤–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –¥–µ—Ñ–µ–∫—Ç–æ–≤
        st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–µ—Ñ–µ–∫—Ç–æ–≤ (—É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø–æ –æ–∫–Ω–∞–º —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏)")
        labels = ["bearing_outer","bearing_inner","rolling","cage","imbalance","misalignment"]
        vals = summary["per_source"]
        if vals.sum() > 0:
            pie_df = pd.DataFrame({"source": labels, "value": vals / (vals.sum() + 1e-9)})
            fig_pie = px.pie(pie_df, names="source", values="value", hole=0.45)
            st.plotly_chart(fig_pie, use_container_width=True)
        else:
            st.caption("–ù–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π ‚Üí —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–æ.")

    st.divider()

    # --- –ë—ã—Å—Ç—Ä—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä —Å—ã—Ä–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –¥–≤–∏–≥–∞—Ç–µ–ª—é ---
    st.subheader("–°—ã—Ä—ã–µ —Å–∏–≥–Ω–∞–ª—ã (—Ñ—Ä–∞–≥–º–µ–Ω—Ç) –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –¥–≤–∏–≥–∞—Ç–µ–ª—é")
    import numpy as np
    device_file = st.selectbox("–î–≤–∏–≥–∞—Ç–µ–ª—å (CSV)", files, index=0, format_func=lambda p: os.path.basename(p))
    show_sec = st.slider("–î–ª–∏–Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ (—Å–µ–∫)", 5, 30, 10)

    x = read_csv_3phase(device_file)
    factor = max(1, FS_RAW // fs_out)
    if factor > 1:
        x = decimate(x, factor)
    fs = FS_RAW // factor
    n = len(x); dur = n / fs

    # –ø–æ–∑–∏—Ü–∏—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞
    pos = st.slider("–ü–æ–∑–∏—Ü–∏—è –Ω–∞—á–∞–ª–∞ (—Å–µ–∫)", 0.0, max(0.0, dur - show_sec), 0.0, 0.5)
    i0 = int(pos * fs); i1 = min(i0 + int(show_sec * fs), n)
    frag = x[i0:i1]

    # downsample –¥–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è
    max_points = 8000
    step = max(1, (i1 - i0) // max_points)
    t = np.arange(i0, i1, step) / fs
    frag_ds = frag[::step]

    fig = go.Figure()
    for i, name in enumerate(["A","B","C"]):
        fig.add_trace(go.Scattergl(x=t, y=frag_ds[:, i], mode="lines", name=name, line=dict(width=1)))
    fig.update_layout(height=320, xaxis_title="–í—Ä–µ–º—è, —Å", yaxis_title="–¢–æ–∫, A",
                      legend=dict(orientation="h", y=1.02, x=1, xanchor="right"))
    st.plotly_chart(fig, use_container_width=True)


elif page.startswith("–ò–ò–º–ø—É–ª—å—Å (–ì–ª–∞–≤–Ω–∞—è)"):
    st.title("–ò–ò–º–ø—É–ª—å—Å ‚Äî –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–æ—Å—Ç–æ—è–Ω–∏—è")
    st.write("–ó–¥–µ—Å—å –±—É–¥–µ—Ç —Å–≤–æ–¥–∫–∞ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º –∞–Ω–∞–ª–∏–∑–∞–º, KPI –º–æ–¥–µ–ª–∏ –∏ —Ç—Ä–µ–Ω–¥—ã.")
    st.info("–î–ª—è —Ç–µ—Å—Ç–∞ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≤–∫–ª–∞–¥–∫—É ¬´–ê–Ω–∞–ª–∏–∑ CSV¬ª, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –∏ –ø–æ–ª—É—á–∏—Ç–µ –ø—Ä–æ–≥–Ω–æ–∑.")
elif page.startswith("–û–±–∑–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞"):
    st.title("–û–±–∑–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ (38 —Ñ–∞–π–ª–æ–≤)")
    st.caption("–õ–∏—Å—Ç–∞–µ–º 38 CSV: –≤—Ä–µ–º—è-—Ä—è–¥, —Å–ø–µ–∫—Ç—Ä, PSD, —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º–∞ –∏ –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –æ–∫–æ–Ω")

elif page.startswith("–ò–ò-–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"):
    # ===== –ó–ê–ì–û–õ–û–í–û–ö =====
    st.title("üîÆ –ò–ò-–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–æ CSV (–úVP)")
    st.caption("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV (3 –∫–æ–ª–æ–Ω–∫–∏ —Ç–æ–∫–∞ A,B,C) ‚Äî –ø–æ–ª—É—á–∏–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–µ—Ñ–µ–∫—Ç–∞, —Ç–∏–ø, severity –∏ TTF.")

    # --- —á—Ç–æ–±—ã –ø–æ–¥—Ö–≤–∞—Ç–∏–ª–∏—Å—å –Ω–∞—à–∏ –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥—É–ª–∏ (inference_v2, features, mvp_model_runtime) ---
    import os, sys, io
    import numpy as np
    import pandas as pd
    import plotly.express as px
    import plotly.graph_objects as go

    sys.path.append(os.path.dirname(__file__))
    from inference_v2 import load_predictor

    # ===== –ú–û–î–ï–õ–¨ (–∫—ç—à —Ä–µ—Å—É—Ä—Å–∞) =====
    @st.cache_resource(show_spinner=False)
    def _load_predictor():
        return load_predictor(model_dir="models")
    predictor = _load_predictor()

    # ===== –°–ê–ô–î–ë–ê–†: –ù–ê–°–¢–†–û–ô–ö–ò =====
    with st.sidebar:
        st.header("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞ (MVP)")
        fs_out  = st.select_slider("–ß–∞—Å—Ç–æ—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏, –ì—Ü", [2000, 3200, 5120], value=3200)
        win_sec = st.select_slider("–û–∫–Ω–æ, —Å–µ–∫", [0.5, 1.0, 2.0], value=1.0)
        overlap = st.select_slider("–ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ", [0.0, 0.25, 0.5], value=0.0)
        st.divider()
        st.header("–ü–æ–¥—à–∏–ø–Ω–∏–∫ / RPM")
        rpm   = st.number_input("RPM", 500, 6000, 1770, step=10)
        Z     = st.number_input("Z (—á–∏—Å–ª–æ —Ç–µ–ª –∫–∞—á–µ–Ω–∏—è)", 3, 20, 9, step=1)
        dmm   = st.number_input("d, –º–º (—à–∞—Ä–∏–∫/—Ä–æ–ª–∏–∫)", value=7.94, step=0.01, format="%.2f")
        Dmm   = st.number_input("D, –º–º (–¥–µ–ª–∏—Ç–µ–ª—å–Ω–∞—è)", value=38.5, step=0.1, format="%.1f")
        theta = st.number_input("–£–≥–æ–ª –∫–æ–Ω—Ç–∞–∫—Ç–∞, ¬∞", value=0, step=1)
        st.caption(f"–ü–æ—Ä–æ–≥ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –∏–∑ –º–æ–¥–µ–ª–∏: **{predictor.info.get('bin_threshold',0.5):.3f}**")

    # ===== –§–ê–ô–õ =====
    up = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Å —Ç—Ä–µ–º—è –∫–æ–ª–æ–Ω–∫–∞–º–∏ (A,B,C)", type=["csv"])
    if not up:
        st.stop()

    data_bytes = up.read()

    # ===== –ò–ù–§–ï–†–ï–ù–° =====
    try:
        with st.spinner("–°—á–∏—Ç–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è..."):
            df_pred, agg = predictor.predict_csv(
                io.BytesIO(data_bytes),
                fs_raw=25600, fs_out=fs_out,
                win_sec=win_sec, overlap=overlap,
                rpm=float(rpm), Z=int(Z), dmm=float(dmm), Dmm=float(Dmm), theta=int(theta)
            )
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: {e}")
        st.stop()

    # ===== KPI / –í–ï–†–î–ò–ö–¢ =====
    thr = agg["thr_bin"]
    verdict = "–î–ï–§–ï–ö–¢" if (agg["p_def_mean"] >= thr or agg["p_def_share_over_thr"] >= 0.2) else "–ù–û–†–ú–ê"
    emoji = "üî¥" if verdict == "–î–ï–§–ï–ö–¢" else "üü¢"

    k1, k2, k3, k4 = st.columns(4)
    k1.metric("–í–µ—Ä–¥–∏–∫—Ç", f"{emoji} {verdict}")
    k2.metric("–°—Ä–µ–¥–Ω—è—è p(defect)", f"{agg['p_def_mean']:.2f}")
    k3.metric("–û–∫–æ–Ω ‚â• –ø–æ—Ä–æ–≥–∞", f"{100*agg['p_def_share_over_thr']:.0f}%")
    k4.metric("TTF –¥–æ severity=80", "‚àû" if np.isinf(agg["ttf_to_80_sec"]) else f"{agg['ttf_to_80_sec']:.0f} c")

    k5, k6, k7 = st.columns(3)
    k5.metric("–ö–ª–∞—Å—Å —Ñ–∞–π–ª–∞ (7)", agg["file_class7"])
    k6.metric("–ö–ª–∞—Å—Å —Ñ–∞–π–ª–∞ (3)", agg["file_class3"])
    k7.metric("Severity avg / max", f"{agg['severity_mean']:.1f} / {agg['severity_max']:.1f}")

    st.divider()

    # ===== –ì–†–ê–§–ò–ö–ò =====
    c1, c2 = st.columns(2)

    with c1:
        st.subheader("–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–µ—Ñ–µ–∫—Ç–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏")
        fig1 = go.Figure()
        fig1.add_trace(go.Scatter(x=df_pred["t1"], y=df_pred["p_def"], mode="lines", name="p(defect)"))
        fig1.add_hline(y=thr, line_dash="dot", annotation_text="–ø–æ—Ä–æ–≥", annotation_position="top left")
        fig1.update_layout(height=280, xaxis_title="–í—Ä–µ–º—è, c", yaxis_title="–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å")
        st.plotly_chart(fig1, use_container_width=True)

    with c2:
        st.subheader("Severity (0..100) –ø–æ –≤—Ä–µ–º–µ–Ω–∏")
        fig2 = go.Figure()
        fig2.add_trace(go.Scatter(x=df_pred["t1"], y=df_pred["severity"], mode="lines", name="severity"))
        fig2.add_hline(y=50, line_dash="dot", annotation_text="warning")
        fig2.add_hline(y=80, line_dash="dot", annotation_text="alarm")
        fig2.update_layout(height=280, xaxis_title="–í—Ä–µ–º—è, c", yaxis_title="Severity")
        st.plotly_chart(fig2, use_container_width=True)

    st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –¥–µ—Ñ–µ–∫—Ç–æ–≤ (—É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø–æ —Ñ–∞–π–ª—É)")
    labels7 = predictor.labels7 if hasattr(predictor, "labels7") else ["normal","BPFO","BPFI","BSF","FTF","imbalance","misalignment"]
    p7 = np.array(agg["file_p7"])
    df_p7 = pd.DataFrame({"class": labels7, "prob": p7})
    fig_p7 = px.bar(df_p7, x="class", y="prob", text="prob")
    fig_p7.update_traces(texttemplate="%{text:.2f}", textposition="outside")
    fig_p7.update_layout(height=280, yaxis_range=[0,1], margin=dict(t=20))
    st.plotly_chart(fig_p7, use_container_width=True)

    # ===== –¢–ê–ë–õ–ò–¶–ê –û–ö–û–ù =====
    st.subheader("–û–∫–Ω–∞ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º —Ä–∏—Å–∫–æ–º")
    top = df_pred.sort_values(["p_def","severity"], ascending=False).head(25)[["t0","t1","p_def","y_pred","severity"]]
    st.dataframe(top, use_container_width=True, height=340)

    # ===== –≠–ö–°–ü–û–†–¢ =====
    st.download_button(
        "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –æ—Ç—á—ë—Ç –ø–æ –æ–∫–Ω–∞–º (CSV)",
        df_pred.to_csv(index=False).encode("utf-8"),
        file_name=f"report_{up.name}.csv",
        mime="text/csv"
    )


elif page.startswith("–¢–û–∏–†"):
    st.title("–¢–û–∏–† ‚Ä¢ –ñ—É—Ä–Ω–∞–ª –ø–æ–ª–æ–º–æ–∫")
    st.caption("–ó–∞–≥—Ä—É–∑–∏ –∂—É—Ä–Ω–∞–ª –∏–ª–∏ —Ä–∞–±–æ—Ç–∞–π –Ω–∞ –¥–µ–º–æ-–¥–∞–Ω–Ω—ã—Ö. –§–∏–ª—å—Ç—Ä—ã ‚Äî —Å–ª–µ–≤–∞.")

    import io, math, re, random
    from datetime import datetime, timedelta
    import pandas as pd
    import numpy as np
    import plotly.express as px
    import plotly.graph_objects as go

    REQUIRED_COLS = [
        "ID –∑–∞–ø–∏—Å–∏", "–î–∞—Ç–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è", "–í—Ä–µ–º—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è", "–¶–µ—Ö / —É—á–∞—Å—Ç–æ–∫",
        "–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ / –¥–≤–∏–≥–∞—Ç–µ–ª—å", "–ò–Ω–≤–µ–Ω—Ç–∞—Ä–Ω—ã–π ‚Ññ / —Å–µ—Ä–∏–π–Ω—ã–π ‚Ññ", "–¢–∏–ø –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è",
        "–¢–∏–ø –ø–æ–ª–æ–º–∫–∏", "–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–∏", "–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å", "–°–æ–∑–¥–∞–Ω–∞ –∑–∞—è–≤–∫–∞",
        "–ù–æ–º–µ—Ä –∑–∞—è–≤–∫–∏", "–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π –∑–∞ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ", "–î–∞—Ç–∞/–≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞—è–≤–∫–∏",
        "–°—Ä–æ–∫ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è (–ø–ª–∞–Ω)", "–î–∞—Ç–∞ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è",
        "–í—Ä–µ–º—è –ø—Ä–æ—Å—Ç–æ—è", "–°—Ç–∞—Ç—É—Å", "–ü—Ä–∏—á–∏–Ω–∞ –ø–æ–ª–æ–º–∫–∏", "–ü—Ä–∏–Ω—è—Ç—ã–µ –º–µ—Ä—ã",
        "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å —Ä–µ–º–æ–Ω—Ç–∞", "–°—Ç–æ–∏–º–æ—Å—Ç—å —Ä–µ–º–æ–Ω—Ç–∞ / –∑–∞–ø—á–∞—Å—Ç–µ–π", "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏"
    ]


    # ---------- helpers ----------
    def _to_bool(x):
        if isinstance(x, str):
            x = x.strip().lower()
        return x in (True, 1, "1", "true", "–¥–∞", "y", "yes", "–æ–∫", "–∏—Å—Ç–∏–Ω–∞")


    @st.cache_data(show_spinner=False)
    def load_uploaded(file):
        if file is None:
            return None
        try:
            if file.name.lower().endswith(".csv"):
                df = pd.read_csv(file)
            else:
                df = pd.read_excel(file, engine="openpyxl")
            return df
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
            return None


    @st.cache_data(show_spinner=False)
    def make_demo(n_rows=1000, days=180, seed=42):
        random.seed(seed);
        np.random.seed(seed)
        today = datetime.now().date()
        shops = [f"–¶–µ—Ö {i}" for i in range(1, 9)]
        types = ["–¥–≤–∏–≥–∞—Ç–µ–ª—å", "—Å—Ç–∞–Ω–æ–∫", "–∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä", "–Ω–∞—Å–æ—Å", "—Ä–µ–¥—É–∫—Ç–æ—Ä"]
        eqs = [f"–î–≤–∏–≥–∞—Ç–µ–ª—å-{i:03d}" for i in range(40, 120)]
        kinds = ["–º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–∞—è", "—ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è", "–≥–∏–¥—Ä–∞–≤–ª–∏–∫–∞", "–ü–û", "—Å–º–∞–∑–∫–∞"]
        reasons = ["–∏–∑–Ω–æ—Å", "–æ—à–∏–±–∫–∞ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞", "–ø–µ—Ä–µ–≥—Ä—É–∑–∫–∞", "–¥–µ—Ñ–µ–∫—Ç –¥–µ—Ç–∞–ª–∏", "–≤–∏–±—Ä–∞—Ü–∏—è", "–∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏–µ"]
        crits = ["–≤—ã—Å–æ–∫–∞—è", "—Å—Ä–µ–¥–Ω—è—è", "–Ω–∏–∑–∫–∞—è"]
        statuses = ["–í —Ä–∞–±–æ—Ç–µ", "–û–∂–∏–¥–∞–µ—Ç –∑–∞–ø—á–∞—Å—Ç–µ–π", "–£—Å—Ç—Ä–∞–Ω–µ–Ω–∞"]
        resp = ["–ò–≤–∞–Ω–æ–≤", "–ü–µ—Ç—Ä–æ–≤", "–°–∏–¥–æ—Ä–æ–≤", "–°–º–∏—Ä–Ω–æ–≤", "–ö—É–∑–Ω–µ—Ü–æ–≤"]
        execs = ["–ê–û –†–µ–º–æ–Ω—Ç–°–µ—Ä–≤–∏—Å", "–û–û–û –¢–µ—Ö–°–∞–ø–ø–æ—Ä—Ç", "–ò–ü –ú–µ—Ö–∞–Ω–∏–∫", "–¶–µ—Ö–æ–≤–∞—è –±—Ä–∏–≥–∞–¥–∞"]

        rows = []
        for i in range(n_rows):
            d0 = today - timedelta(days=int(np.random.beta(2, 6) * days))
            # –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–∞–ª–∏—á–∏—è –≤—Ä–µ–º–µ–Ω–∏
            t0 = (datetime(2000, 1, 1, 8, 0) + timedelta(
                minutes=int(np.random.rand() * 600))).time() if np.random.rand() < 0.8 else None
            sh = random.choice(shops)
            tp = random.choice(types)
            eq = random.choice(eqs)
            kind = np.random.choice(kinds, p=[0.36, 0.32, 0.1, 0.12, 0.1])
            crit = np.random.choice(crits, p=[0.25, 0.5, 0.25])
            stt = np.random.choice(statuses, p=[0.25, 0.15, 0.60])
            created_dt = datetime.combine(d0, t0 or datetime.min.time()) + timedelta(hours=np.random.uniform(0, 6))
            plan_dt = created_dt + timedelta(hours=np.random.uniform(4, 72))
            closed = (stt == "–£—Å—Ç—Ä–∞–Ω–µ–Ω–∞") and (np.random.rand() < 0.9)
            fix_dt = created_dt + timedelta(hours=np.random.uniform(2, 48)) if closed else pd.NaT
            downtime = float(np.round(np.random.uniform(0.5, 24), 2)) if closed else np.nan
            cost = float(np.round(np.exp(np.random.normal(6, 0.9)) / 100, 2)) if closed else np.nan  # ~–ª–æ–≥–Ω–æ—Ä–º
            rows.append({
                "ID –∑–∞–ø–∏—Å–∏": i + 1,
                "–î–∞—Ç–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è": d0,
                "–í—Ä–µ–º—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è": t0,
                "–¶–µ—Ö / —É—á–∞—Å—Ç–æ–∫": sh,
                "–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ / –¥–≤–∏–≥–∞—Ç–µ–ª—å": eq,
                "–ò–Ω–≤–µ–Ω—Ç–∞—Ä–Ω—ã–π ‚Ññ / —Å–µ—Ä–∏–π–Ω—ã–π ‚Ññ": f"INV-{10000 + i}",
                "–¢–∏–ø –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è": tp,
                "–¢–∏–ø –ø–æ–ª–æ–º–∫–∏": kind,
                "–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–∏": f"–°–∏–º–ø—Ç–æ–º—ã {kind} –Ω–∞ {eq}",
                "–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å": crit,
                "–°–æ–∑–¥–∞–Ω–∞ –∑–∞—è–≤–∫–∞": "–î–∞" if np.random.rand() < 0.85 else "–ù–µ—Ç",
                "–ù–æ–º–µ—Ä –∑–∞—è–≤–∫–∏": f"REQ-{200000 + i}" if np.random.rand() < 0.85 else "",
                "–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π –∑–∞ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ": random.choice(resp),
                "–î–∞—Ç–∞/–≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞—è–≤–∫–∏": created_dt,
                "–°—Ä–æ–∫ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è (–ø–ª–∞–Ω)": plan_dt,
                "–î–∞—Ç–∞ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è": fix_dt,
                "–í—Ä–µ–º—è –ø—Ä–æ—Å—Ç–æ—è": downtime,
                "–°—Ç–∞—Ç—É—Å": stt,
                "–ü—Ä–∏—á–∏–Ω–∞ –ø–æ–ª–æ–º–∫–∏": np.random.choice(reasons, p=[0.35, 0.15, 0.15, 0.1, 0.15, 0.10]),
                "–ü—Ä–∏–Ω—è—Ç—ã–µ –º–µ—Ä—ã": "–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞/—Ä–µ–º–æ–Ω—Ç/–∑–∞–º–µ–Ω–∞",
                "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å —Ä–µ–º–æ–Ω—Ç–∞": random.choice(execs),
                "–°—Ç–æ–∏–º–æ—Å—Ç—å —Ä–µ–º–æ–Ω—Ç–∞ / –∑–∞–ø—á–∞—Å—Ç–µ–π": cost,
                "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏": ""
            })
        df = pd.DataFrame(rows)
        return df


    def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
        # —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –µ—Å—Ç—å
        missing = [c for c in REQUIRED_COLS if c not in df.columns]
        if missing:
            st.error("–ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –∫–æ–ª–æ–Ω–æ–∫: " + ", ".join(missing))
        # –ø—Ä–∏–≤–µ–¥—ë–º —Ç–∏–ø—ã
        df = df.copy()
        # –¥–∞—Ç—ã/–≤—Ä–µ–º—è
        df["–î–∞—Ç–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è"] = pd.to_datetime(df["–î–∞—Ç–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è"], errors="coerce").dt.date
        if "–í—Ä–µ–º—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è" in df:
            df["–í—Ä–µ–º—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è"] = pd.to_datetime(df["–í—Ä–µ–º—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è"], errors="coerce").dt.time
        df["–î–∞—Ç–∞/–≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞—è–≤–∫–∏"] = pd.to_datetime(df["–î–∞—Ç–∞/–≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞—è–≤–∫–∏"], errors="coerce")
        df["–°—Ä–æ–∫ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è (–ø–ª–∞–Ω)"] = pd.to_datetime(df["–°—Ä–æ–∫ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è (–ø–ª–∞–Ω)"], errors="coerce")
        df["–î–∞—Ç–∞ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è"] = pd.to_datetime(df["–î–∞—Ç–∞ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è"], errors="coerce")
        # —á–∏—Å–ª–∞/–±—É–ª–µ–≤—ã–µ
        df["–°–æ–∑–¥–∞–Ω–∞ –∑–∞—è–≤–∫–∞"] = df["–°–æ–∑–¥–∞–Ω–∞ –∑–∞—è–≤–∫–∞"].map(_to_bool)
        for col in ["–í—Ä–µ–º—è –ø—Ä–æ—Å—Ç–æ—è", "–°—Ç–æ–∏–º–æ—Å—Ç—å —Ä–µ–º–æ–Ω—Ç–∞ / –∑–∞–ø—á–∞—Å—Ç–µ–π"]:
            df[col] = pd.to_numeric(df[col], errors="coerce")
        # –≤—ã—á–∏—Å–ª—è–µ–º—ã–µ –ø–æ–ª—è
        ts_detect = pd.to_datetime(df["–î–∞—Ç–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è"], errors="coerce")
        if "–í—Ä–µ–º—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è" in df and df["–í—Ä–µ–º—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è"].notna().any():
            # –µ—Å–ª–∏ –µ—Å—Ç—å –≤—Ä–µ–º—è ‚Äî –¥–æ–±–∞–≤–∏–º –µ–≥–æ
            tcomp = pd.to_datetime(df["–í—Ä–µ–º—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è"].astype(str), errors="coerce").dt.time
            ts_detect = pd.to_datetime(df["–î–∞—Ç–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è"].astype(str) + " " + df["–í—Ä–µ–º—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è"].astype(str),
                                       errors="coerce")
        df["__ts_detect"] = ts_detect
        # –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è, —á
        mask_closed = df["–î–∞—Ç–∞ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è"].notna()
        delta = df.loc[mask_closed, "–î–∞—Ç–∞ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è"] - df.loc[mask_closed, "__ts_detect"]
        df["–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è, —á"] = np.nan
        df.loc[mask_closed, "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è, —á"] = (delta.dt.total_seconds() / 3600.0).clip(lower=0)
        return df


    def apply_filters(df: pd.DataFrame) -> pd.DataFrame:
        with st.sidebar:
            st.subheader("–§–∏–ª—å—Ç—Ä—ã –∂—É—Ä–Ω–∞–ª–∞")
            min_d = pd.to_datetime(df["__ts_detect"]).min()
            max_d = pd.to_datetime(df["__ts_detect"]).max()
            d_from, d_to = st.date_input("–ü–µ—Ä–∏–æ–¥ (–î–∞—Ç–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è)", (min_d.date(), max_d.date()))
            shop = st.multiselect("–¶–µ—Ö / —É—á–∞—Å—Ç–æ–∫", sorted(df["–¶–µ—Ö / —É—á–∞—Å—Ç–æ–∫"].dropna().unique().tolist()))
            tpe = st.multiselect("–¢–∏–ø –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è", sorted(df["–¢–∏–ø –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è"].dropna().unique().tolist()))
            equip = st.multiselect("–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ / –¥–≤–∏–≥–∞—Ç–µ–ª—å",
                                   sorted(df["–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ / –¥–≤–∏–≥–∞—Ç–µ–ª—å"].dropna().unique().tolist()))
            kind = st.multiselect("–¢–∏–ø –ø–æ–ª–æ–º–∫–∏", sorted(df["–¢–∏–ø –ø–æ–ª–æ–º–∫–∏"].dropna().unique().tolist()))
            crit = st.multiselect("–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å", ["–≤—ã—Å–æ–∫–∞—è", "—Å—Ä–µ–¥–Ω—è—è", "–Ω–∏–∑–∫–∞—è"])
            stat = st.multiselect("–°—Ç–∞—Ç—É—Å", sorted(df["–°—Ç–∞—Ç—É—Å"].dropna().unique().tolist()))
            only_closed = st.checkbox("–¢–æ–ª—å–∫–æ –∑–∞–∫—Ä—ã—Ç—ã–µ –∏–Ω—Ü–∏–¥–µ–Ω—Ç—ã", value=False)
            q = st.text_input("–ü–æ–∏—Å–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏/–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö")

        m = (pd.to_datetime(df["__ts_detect"]).dt.date >= d_from) & (pd.to_datetime(df["__ts_detect"]).dt.date <= d_to)
        if shop: m &= df["–¶–µ—Ö / —É—á–∞—Å—Ç–æ–∫"].isin(shop)
        if tpe:  m &= df["–¢–∏–ø –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è"].isin(tpe)
        if equip: m &= df["–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ / –¥–≤–∏–≥–∞—Ç–µ–ª—å"].isin(equip)
        if kind: m &= df["–¢–∏–ø –ø–æ–ª–æ–º–∫–∏"].isin(kind)
        if crit: m &= df["–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å"].isin(crit)
        if stat: m &= df["–°—Ç–∞—Ç—É—Å"].isin(stat)
        if only_closed: m &= df["–î–∞—Ç–∞ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è"].notna()
        if q:
            ql = q.strip().lower()
            m &= (df["–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–∏"].astype(str).str.lower().str.contains(ql)) | \
                 (df["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏"].astype(str).str.lower().str.contains(ql))
        return df[m].copy()


    def kpi_cards(df: pd.DataFrame):
        c1, c2, c3, c4 = st.columns(4)
        total = len(df)
        c1.metric("–ü–æ–ª–æ–º–æ–∫ –∑–∞ –ø–µ—Ä–∏–æ–¥", f"{total}")
        mttr = df["–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è, —á"].dropna().mean()
        c2.metric("MTTR, —á", "‚Äî" if np.isnan(mttr) else f"{mttr:.1f}")
        # MTBF –ø–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é
        mtbf_vals = []
        for eq, g in df.sort_values("__ts_detect").groupby("–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ / –¥–≤–∏–≥–∞—Ç–µ–ª—å"):
            times = pd.to_datetime(g["__ts_detect"]).values
            if len(times) >= 2:
                diffs = np.diff(times).astype("timedelta64[h]").astype(float)
                if len(diffs) > 0: mtbf_vals.append(diffs.mean())
        mtbf = np.mean(mtbf_vals) if mtbf_vals else np.nan
        c3.metric("MTBF, —á", "‚Äî" if (not mtbf_vals or np.isnan(mtbf)) else f"{mtbf:.0f}")
        # –î–æ–ª—è ¬´–≤ —Å—Ä–æ–∫¬ª
        closed = df[df["–î–∞—Ç–∞ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è"].notna()].copy()
        if len(closed):
            ontime = (closed["–î–∞—Ç–∞ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è"] <= closed["–°—Ä–æ–∫ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è (–ø–ª–∞–Ω)"]).mean() * 100
            c4.metric("–î–æ–ª—è ¬´–≤ —Å—Ä–æ–∫¬ª, %", f"{ontime:.0f}")
        else:
            c4.metric("–î–æ–ª—è ¬´–≤ —Å—Ä–æ–∫¬ª, %", "‚Äî")
        st.caption(
            "MTTR ‚Äî —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –ø–æ –∑–∞–∫—Ä—ã—Ç—ã–º –∏–Ω—Ü–∏–¥–µ–Ω—Ç–∞–º. MTBF ‚Äî —Å—Ä–µ–¥–Ω–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –æ—Ç–∫–∞–∑–∞–º–∏ –ø–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é —Å ‚â•2 —Å–æ–±—ã—Ç–∏—è–º–∏. ¬´–í —Å—Ä–æ–∫¬ª ‚Äî —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ñ–∞–∫—Ç–∞ –∏ –ø–ª–∞–Ω–∞.")


    def export_buttons(df: pd.DataFrame, fname_prefix="journal_filtered"):
        csv = df.to_csv(index=False).encode("utf-8")
        st.download_button("–°–∫–∞—á–∞—Ç—å –¥–∞–Ω–Ω—ã–µ (CSV)", csv, file_name=f"{fname_prefix}.csv", mime="text/csv")
        try:
            import io
            bio = io.BytesIO()
            with pd.ExcelWriter(bio, engine="openpyxl") as wr:
                df.to_excel(wr, index=False, sheet_name="data")
            st.download_button("–°–∫–∞—á–∞—Ç—å –¥–∞–Ω–Ω—ã–µ (XLSX)", bio.getvalue(), file_name=f"{fname_prefix}.xlsx",
                               mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        except Exception:
            st.caption("–î–ª—è XLSX —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–∞–∫–µ—Ç openpyxl.")


    # ---------- –∑–∞–≥—Ä—É–∑–∫–∞/–¥–µ–º–æ ----------
    with st.sidebar:
        st.subheader("–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö")
        upl = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å –∂—É—Ä–Ω–∞–ª (CSV/XLSX)", type=["csv", "xlsx"], key="toir_upload")
    df_raw = load_uploaded(upl)
    if df_raw is None:
        df_raw = make_demo()

    df = normalize_df(df_raw)

    # ---------- —Ñ–∏–ª—å—Ç—Ä—ã + KPI ----------
    dff = apply_filters(df)
    kpi_cards(dff)

    # ---------- –≤–∫–ª–∞–¥–∫–∏ ----------
    tab0, tab1, tab2, tab3, tab4, tab5 = st.tabs(
        ["–û–±—â–µ–µ", "–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ", "–¢–∏–ø—ã –ø–æ–ª–æ–º–æ–∫", "–°—Ä–æ–∫–∏ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å", "–§–∏–Ω–∞–Ω—Å—ã", "–ü—Ä–æ–≥–Ω–æ–∑"]
    )

    with tab0:
        fr = st.radio("–®–∞–≥ –≤—Ä–µ–º–µ–Ω–∏", ["–î–µ–Ω—å", "–ù–µ–¥–µ–ª—è", "–ú–µ—Å—è—Ü"], horizontal=True)
        code = {"–î–µ–Ω—å": "D", "–ù–µ–¥–µ–ª—è": "W", "–ú–µ—Å—è—Ü": "M"}[fr]
        ts = dff.set_index(pd.to_datetime(dff["__ts_detect"])).sort_index()
        if len(ts):
            trend = ts["ID –∑–∞–ø–∏—Å–∏"].resample(code).count().rename("count").to_frame()
            fig = px.line(trend, y="count", markers=True)
            fig.update_layout(height=320, xaxis_title="–î–∞—Ç–∞", yaxis_title="–ö–æ–ª-–≤–æ")
            st.plotly_chart(fig, use_container_width=True)
            # stacked bar –ø–æ –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏
            gb = ts.groupby([pd.Grouper(freq=code), "–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å"])["ID –∑–∞–ø–∏—Å–∏"].count().reset_index()
            fig2 = px.bar(gb, x="__ts_detect", y="ID –∑–∞–ø–∏—Å–∏", color="–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å", barmode="stack")
            fig2.update_layout(height=320, xaxis_title="–î–∞—Ç–∞", yaxis_title="–ö–æ–ª-–≤–æ")
            st.plotly_chart(fig2, use_container_width=True)
        else:
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤.")
        st.subheader("–ü–æ—Å–ª–µ–¥–Ω–∏–µ –∏–Ω—Ü–∏–¥–µ–Ω—Ç—ã")
        st.dataframe(dff.sort_values("__ts_detect", ascending=False).head(20), use_container_width=True)
        export_buttons(dff)

    with tab1:
        c = dff["–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ / –¥–≤–∏–≥–∞—Ç–µ–ª—å"].value_counts().head(5).reset_index()
        c.columns = ["–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ / –¥–≤–∏–≥–∞—Ç–µ–ª—å", "–ö–æ–ª-–≤–æ"]
        fig = px.bar(c, x="–ö–æ–ª-–≤–æ", y="–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ / –¥–≤–∏–≥–∞—Ç–µ–ª—å", orientation="h")
        fig.update_layout(height=320)
        st.plotly_chart(fig, use_container_width=True)
        # heatmap —Ü–µ—Ö √ó —Ç–∏–ø –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
        pv = dff.pivot_table(index="–¢–∏–ø –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è", columns="–¶–µ—Ö / —É—á–∞—Å—Ç–æ–∫", values="ID –∑–∞–ø–∏—Å–∏", aggfunc="count",
                             fill_value=0)
        fig2 = px.imshow(pv, text_auto=True, aspect="auto")
        st.plotly_chart(fig2, use_container_width=True)
        # —Å—É–º–º–∞—Ä–Ω—ã–π –ø—Ä–æ—Å—Ç–æ–π
        down = dff.groupby("–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ / –¥–≤–∏–≥–∞—Ç–µ–ª—å")["–í—Ä–µ–º—è –ø—Ä–æ—Å—Ç–æ—è"].sum().sort_values(ascending=False).head(10)
        fig3 = px.bar(down.reset_index(), x="–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ / –¥–≤–∏–≥–∞—Ç–µ–ª—å", y="–í—Ä–µ–º—è –ø—Ä–æ—Å—Ç–æ—è")
        fig3.update_layout(height=320, xaxis_title="–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ", yaxis_title="–°—É–º–º–∞—Ä–Ω—ã–π –ø—Ä–æ—Å—Ç–æ–π, —á")
        st.plotly_chart(fig3, use_container_width=True)

    with tab2:
        pie = dff["–¢–∏–ø –ø–æ–ª–æ–º–∫–∏"].value_counts(normalize=True).reset_index()
        pie.columns = ["–¢–∏–ø –ø–æ–ª–æ–º–∫–∏", "–î–æ–ª—è"]
        fig = px.pie(pie, names="–¢–∏–ø –ø–æ–ª–æ–º–∫–∏", values="–î–æ–ª—è", hole=0.4)
        st.plotly_chart(fig, use_container_width=True)
        sum_down = dff.groupby("–¢–∏–ø –ø–æ–ª–æ–º–∫–∏")["–í—Ä–µ–º—è –ø—Ä–æ—Å—Ç–æ—è"].sum().reset_index()
        fig2 = px.bar(sum_down, x="–¢–∏–ø –ø–æ–ª–æ–º–∫–∏", y="–í—Ä–µ–º—è –ø—Ä–æ—Å—Ç–æ—è")
        fig2.update_layout(height=320, yaxis_title="–°—É–º–º–∞—Ä–Ω—ã–π –ø—Ä–æ—Å—Ç–æ–π, —á")
        st.plotly_chart(fig2, use_container_width=True)
        st.subheader("–ü–æ–≤—Ç–æ—Ä—è–µ–º–æ—Å—Ç—å –¥–µ—Ñ–µ–∫—Ç–æ–≤ (—Ç–∏–ø √ó –ø—Ä–∏—á–∏–Ω–∞)")
        tbl = dff.pivot_table(index="–¢–∏–ø –ø–æ–ª–æ–º–∫–∏", columns="–ü—Ä–∏—á–∏–Ω–∞ –ø–æ–ª–æ–º–∫–∏", values="ID –∑–∞–ø–∏—Å–∏", aggfunc="count",
                              fill_value=0)
        st.dataframe(tbl, use_container_width=True)

    with tab3:
        closed = dff[dff["–î–∞—Ç–∞ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è"].notna()].copy()
        if len(closed):
            ontime = (closed["–î–∞—Ç–∞ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è"] <= closed["–°—Ä–æ–∫ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è (–ø–ª–∞–Ω)"]).mean()
            fig = px.bar(x=["–í —Å—Ä–æ–∫", "–ü—Ä–æ—Å—Ä–æ—á–µ–Ω—ã"], y=[ontime * 100, (1 - ontime) * 100])
            fig.update_layout(height=300, yaxis_title="%")
            st.plotly_chart(fig, use_container_width=True)
            mttr_by = closed.groupby("–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π –∑–∞ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ")["–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è, —á"].mean().sort_values()
            fig2 = px.bar(mttr_by.reset_index(), x="–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π –∑–∞ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ", y="–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è, —á")
            fig2.update_layout(height=320)
            st.plotly_chart(fig2, use_container_width=True)
            # ¬´–ì–∞–Ω—Ç—Ç¬ª
            g = closed.dropna(subset=["–î–∞—Ç–∞/–≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞—è–≤–∫–∏", "–î–∞—Ç–∞ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è"]).copy()
            if len(g):
                import plotly.express as px

                fig3 = px.timeline(
                    g, x_start="–î–∞—Ç–∞/–≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞—è–≤–∫–∏", x_end="–î–∞—Ç–∞ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è",
                    y="–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ / –¥–≤–∏–≥–∞—Ç–µ–ª—å", color="–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å", hover_data=["–°—Ç–∞—Ç—É—Å", "–¢–∏–ø –ø–æ–ª–æ–º–∫–∏"]
                )
                fig3.update_yaxes(autorange="reversed")
                st.plotly_chart(fig3, use_container_width=True)
            else:
                st.caption("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞—Ç –¥–ª—è –¥–∏–∞–≥—Ä–∞–º–º—ã –ì–∞–Ω—Ç–∞.")
        else:
            st.info("–ù–µ—Ç –∑–∞–∫—Ä—ã—Ç—ã—Ö –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤ –¥–ª—è —ç—Ç–æ–π –≤–∫–ª–∞–¥–∫–∏.")

    with tab4:
        cost_by_eq = dff.groupby("–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ / –¥–≤–∏–≥–∞—Ç–µ–ª—å")["–°—Ç–æ–∏–º–æ—Å—Ç—å —Ä–µ–º–æ–Ω—Ç–∞ / –∑–∞–ø—á–∞—Å—Ç–µ–π"].sum().sort_values(
            ascending=False).head(10)
        fig = px.bar(cost_by_eq.reset_index(), x="–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ / –¥–≤–∏–≥–∞—Ç–µ–ª—å", y="–°—Ç–æ–∏–º–æ—Å—Ç—å —Ä–µ–º–æ–Ω—Ç–∞ / –∑–∞–ø—á–∞—Å—Ç–µ–π")
        fig.update_layout(height=320, yaxis_title="–°—É–º–º–∞, —É.–µ.")
        st.plotly_chart(fig, use_container_width=True)
        cost_by_type = dff.groupby("–¢–∏–ø –ø–æ–ª–æ–º–∫–∏")["–°—Ç–æ–∏–º–æ—Å—Ç—å —Ä–µ–º–æ–Ω—Ç–∞ / –∑–∞–ø—á–∞—Å—Ç–µ–π"].sum().reset_index()
        fig2 = px.bar(cost_by_type, x="–¢–∏–ø –ø–æ–ª–æ–º–∫–∏", y="–°—Ç–æ–∏–º–æ—Å—Ç—å —Ä–µ–º–æ–Ω—Ç–∞ / –∑–∞–ø—á–∞—Å—Ç–µ–π")
        st.plotly_chart(fig2, use_container_width=True)
        # bubble: —Å—Ç–æ–∏–º–æ—Å—Ç—å vs –ø—Ä–æ—Å—Ç–æ–π
        agg = dff.groupby("–¢–∏–ø –ø–æ–ª–æ–º–∫–∏").agg(
            –°—Ç–æ–∏–º–æ—Å—Ç—å=("–°—Ç–æ–∏–º–æ—Å—Ç—å —Ä–µ–º–æ–Ω—Ç–∞ / –∑–∞–ø—á–∞—Å—Ç–µ–π", "sum"),
            –ü—Ä–æ—Å—Ç–æ–π=("–í—Ä–µ–º—è –ø—Ä–æ—Å—Ç–æ—è", "sum"),
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ=("ID –∑–∞–ø–∏—Å–∏", "count")
        ).reset_index()
        fig3 = px.scatter(agg, x="–°—Ç–æ–∏–º–æ—Å—Ç—å", y="–ü—Ä–æ—Å—Ç–æ–π", size="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", color="–¢–∏–ø –ø–æ–ª–æ–º–∫–∏",
                          hover_name="–¢–∏–ø –ø–æ–ª–æ–º–∫–∏")
        fig3.update_layout(height=320)
        st.plotly_chart(fig3, use_container_width=True)

    with tab5:
        # –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–≥–Ω–æ–∑ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–æ–ª–æ–º–æ–∫ –ø–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é (—Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ + —ç–∫—Å—Ç—Ä–∞)
        eq_sel = st.selectbox(
            "–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞",
            sorted(dff["–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ / –¥–≤–∏–≥–∞—Ç–µ–ª—å"].dropna().unique())
        )

        sub = dff[dff["–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ / –¥–≤–∏–≥–∞—Ç–µ–ª—å"] == eq_sel].copy()
        sub["__ts_detect"] = pd.to_datetime(sub["__ts_detect"])
        sub = sub.dropna(subset=["__ts_detect"])  # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π

        ts = sub.set_index("__ts_detect").sort_index()

        if len(ts):
            weekly = ts["ID –∑–∞–ø–∏—Å–∏"].resample("W").count().rename("count").to_frame()
            weekly["sma"] = weekly["count"].rolling(3, min_periods=1).mean()
            last = weekly["sma"].iloc[-1]
            fut = pd.DataFrame({"sma": [last] * 4},
                               index=pd.date_range(weekly.index.max() + pd.Timedelta(days=7),
                                                   periods=4, freq="W"))
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=weekly.index, y=weekly["count"], mode="lines+markers", name="–§–∞–∫—Ç/–Ω–µ–¥–µ–ª—è"))
            fig.add_trace(go.Scatter(x=weekly.index, y=weekly["sma"], mode="lines", name="SMA(3)"))
            fig.add_trace(go.Scatter(x=fut.index, y=fut["sma"], mode="lines", name="–ü—Ä–æ–≥–Ω–æ–∑",
                                     line=dict(dash="dash")))
            fig.update_layout(height=320, xaxis_title="–ù–µ–¥–µ–ª—è", yaxis_title="–ö–æ–ª-–≤–æ")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é.")
        # –∫–∞–Ω–¥–∏–¥–∞—Ç—ã –Ω–∞ –¢–û
        st.subheader("–ö–∞–Ω–¥–∏–¥–∞—Ç—ã –Ω–∞ –ø–ª–∞–Ω–æ–≤–æ–µ –¢–û")
        risks = []
        for eq, g in dff.sort_values("__ts_detect").groupby("–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ / –¥–≤–∏–≥–∞—Ç–µ–ª—å"):
            times = pd.to_datetime(g["__ts_detect"]).values
            if len(times) >= 3:
                diffs = np.diff(times).astype("timedelta64[h]").astype(float)
                risks.append({"–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ / –¥–≤–∏–≥–∞—Ç–µ–ª—å": eq, "MTBF, —á": float(np.mean(diffs)), "–°–æ–±—ã—Ç–∏–π": len(g)})
        if risks:
            r = pd.DataFrame(risks).sort_values(["MTBF, —á", "–°–æ–±—ã—Ç–∏–π"], ascending=[True, False]).head(5)
            st.dataframe(r, use_container_width=True)
        else:
            st.caption("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è —Å–æ–±—ã—Ç–∏–π –¥–ª—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Å–ø–∏—Å–∫–∞.")

    st.divider()
    st.caption(
        "–≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ–π —Ç–µ–∫—É—â–µ–π –≤—ã–±–æ—Ä–∫–∏ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–æ –≤–∫–ª–∞–¥–∫–µ ¬´–û–±—â–µ–µ¬ª. –î–ª—è PNG-—ç–∫—Å–ø–æ—Ä—Ç–∞ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –º–æ–∂–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–∞–∫–µ—Ç `kaleido`.")

else:
    st.title("–ê–Ω–∞–ª–∏–∑ CSV")
    fs_out = st.select_slider("–ß–∞—Å—Ç–æ—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ì—Ü)", options=[2000, 3200, 5120], value=3200)
    win = st.slider("–û–∫–Ω–æ (—Å–µ–∫)", 0.5, 2.0, 1.0, 0.5)
    up = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV (3 –∫–æ–ª–æ–Ω–∫–∏ —Ç–æ–∫–∞)", type=["csv"])
    if up is not None:
        # –ø–æ–∫–∞–∑—ã–≤–∞–µ–º ¬´—Å—ã—Ä–æ–µ¬ª
        raw = pd.read_csv(up)
        st.subheader("–°—ã—Ä—ã–µ —Å–∏–≥–Ω–∞–ª—ã (—Ñ—Ä–∞–≥–º–µ–Ω—Ç)")
        st.line_chart(raw.head(500))
        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ –≤ –ø–∞–º—è—Ç—å
        up.seek(0); data_bytes = up.read()
        tmp = io.BytesIO(data_bytes)
        # –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        with st.spinner("–°—á–∏—Ç–∞–µ–º..."):
            # —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ: tmp_path = "/tmp/upload.csv"
            preds = predict_csv(io.BytesIO(data_bytes), fs_out=fs_out, win_sec=win, overlap=0.0)
        df = pd.DataFrame(preds)
        st.subheader("–¢–∞–π–º–ª–∞–π–Ω –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∏ —Å—Ç–µ–ø–µ–Ω–∏")
        c1, c2 = st.columns(2)
        with c1:
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=df.t1, y=df.p_fault, name="p(defect)"))
            st.plotly_chart(fig, use_container_width=True)
        with c2:
            fig2 = go.Figure()
            fig2.add_trace(go.Scatter(x=df.t1, y=df.severity, name="severity (0..100)"))
            st.plotly_chart(fig2, use_container_width=True)

        st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º –¥–µ—Ñ–µ–∫—Ç–æ–≤ (—Å—Ä–µ–¥–Ω–µ–µ –ø–æ —Ñ–∞–π–ª—É)")
        cls = ["bearing_outer","bearing_inner","rolling","cage","imbalance","misalignment"]
        avg = np.array(df['proba'].tolist()).mean(axis=0)
        st.bar_chart(pd.DataFrame({"p":avg}, index=cls))

        st.download_button("–°–∫–∞—á–∞—Ç—å –æ—Ç—á—ë—Ç (CSV)", df.to_csv(index=False).encode("utf-8"), file_name="report.csv")
